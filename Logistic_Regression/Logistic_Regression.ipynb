{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Logistic regression (despite its name) is a supervised classification model.  Recall that in supervised learning we have training data that consists of a set of pairs $\\{ \\, ( \\mathbf{x}_1,y_1 ), ( \\mathbf{x}_2,y_2 ) \\ldots,  ( \\mathbf{x}_m,y_m ) \\, \\}$, where each $\\mathbf{x}_i$ is a feature vector and the target variable $y_i$ is the corresponding label.  In a classification problem, each $y_i$ takes values in a finite unordered set, and we want to find a function $h_\\theta$ that takes a feature vector $\\mathbf{x}_i$ and tries to predict the target variable $y_i$.  We want this function to generalize as well as possible to new data.  An example of such a function $h_\\theta$ would be a spam classifier that takes email data as input and tries to predict whether it is spam or not. \n",
    "\n",
    "Often we are interested in estimating the *probability* of a particular label, given some data. In **logistic regression**, we want to model the probability of a class label $y$ given a number of features $x_1, x_2, \\ldots, x_n$.  Let's start with the case where the target variable is binary, so $y$ can only take the values 0 or 1.  Given a feature vector $\\mathbf{x} = (x_1, \\ldots, x_n)^T$, our function $h_\\theta(\\mathbf{x})$ should estimate the probability that $y$ takes a specfied value in the set $ \\{ 0,1 \\} $.  For example, financial institutions are interested in predicting whether credit card transactions are fraudulent.  It is more valuable to have an estimate of the probability that a transaction is fraudulent, rather than a classification of fraudulent or not.  In such a model, 0 could represent 'not fraudulent' and 1 could represent 'fraudulent', and the function $h_\\theta$ would predict the probability that a credit card transaction is fraudulent based on some features $\\mathbf{x}$.\n",
    "\n",
    "So what is a good candidate for a function $h_\\theta$? We could try to mimic linear regression by attempting to find parameters $\\theta_0, \\theta_1, \\ldots, \\theta_n$ in order to fit a linear function of the form\n",
    "\n",
    "$$ h_\\theta(\\mathbf{x}) = \\theta_0 + \\theta_1 x_1 + \\ldots + \\theta_n x_n \\,, $$\n",
    "\n",
    "but this is not ideal for a few reasons; one of the reasons being that some of the predicted probabilities would fall outside the interval [0,1].  For a discussion, see the text [Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) - Section 4.2.  \n",
    "\n",
    "It turns out that a good model for these probabilities is the **logistic function**\n",
    "\n",
    "$$ g(z) = \\frac{1}{1 + e^{-z}} \\,. $$\n",
    "\n",
    "when $z$ is written as a linear combination of the features  \n",
    "\n",
    "$$ z = \\theta_0 + \\theta_1 x_1 + \\ldots + \\theta_n x_n = \\theta^T \\mathbf{x} \\,. $$  \n",
    "\n",
    "The logistic function takes values in the unit interval [0,1] and it satisfies\n",
    "\n",
    "$$ \\lim_{z \\rightarrow -\\infty} g(z) = 0 \\quad \\mathrm{and} \\quad \\lim_{z \\rightarrow \\infty} g(z) = 1 \\,. $$\n",
    "\n",
    "A graph of the logistic function is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6XFZ+tcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107155668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def logistic(z):\n",
    "    \n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# plot the function\n",
    "x = np.arange(-10, 11)\n",
    "plt.plot(x, logistic(x), color = 'blue')\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('g(z)', rotation = 0, labelpad = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the function $h_\\theta$ ( the function we will use to make predictions ) as follows:\n",
    "\n",
    "$$ h_\\theta(\\mathbf{x}) = g(\\theta^T \\mathbf{x}) = \\frac{1}{1 + e^{ \\, -\\theta^T \\mathbf{x}} } \\,. $$\n",
    "\n",
    "This function $h_\\theta$ will model the probability of a class label $y = 1$ given the feature vector $\\mathbf{x}$, and parametrized by $\\theta$\n",
    "\n",
    "$$ P(y = 1 \\,|\\, \\mathbf{x} ; \\theta) = h_\\theta(\\mathbf{x}) \\,. $$\n",
    "\n",
    "Since there are only two classes ( 0 and 1 ), the probability that $y = 0$, given $\\mathbf{x}$ and parametrized by $\\theta$, can be written as\n",
    "\n",
    "$$ P(y = 0 \\,|\\, \\mathbf{x} ; \\theta) = 1 - h_\\theta(\\mathbf{x}) \\,. $$\n",
    "\n",
    "An important thing to note is that we are treating $\\mathbf{x}$ as a multivariate random variable and $\\theta$ as a vector of parameters that we are trying to estimate.  Observe that we can write\n",
    " \n",
    "$$ P(y \\,|\\, \\mathbf{x} ; \\theta) = h_\\theta(\\mathbf{x})^y (1 - h_\\theta(\\mathbf{x}))^{1-y} \\, \\qquad (1) $$\n",
    "\n",
    "since $y$ can only be one of the two values 0 or 1.  Now suppose that we have $m$ training examples $\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_m$ that we put as the rows of a feature matrix $X$, and we also have the target vector $\\mathbf{y}$ that holds the $m$ labels\n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{bmatrix}\n",
    "\\, - \\,\\, \\mathbf{x}_1^T - \\, \\\\\n",
    "\\, - \\,\\, \\mathbf{x}_2^T - \\, \\\\\n",
    "\\vdots \\\\\n",
    "\\, - \\,\\, \\mathbf{x}_m^T - \\,\n",
    "\\end{bmatrix} \\, , \\quad\n",
    "\\mathbf{y} = \n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_m\n",
    "\\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "Using the matrix $X$ and the vector $\\mathbf{y}$, the probability of the data is written as \n",
    "\n",
    "$$ P(\\mathbf{y} \\,|\\, X; \\theta) \\,. $$  \n",
    "\n",
    "When $P(\\mathbf{y} \\,|\\, X; \\theta)$ is considered as a function of the parameters $\\theta = (\\theta_0, \\theta_1, \\ldots, \\theta_n)^T$, then we give this function a special name, the **likelihood function** ( see [here](https://en.wikipedia.org/wiki/Likelihood_function) ).  The notation we use is\n",
    "\n",
    "$$ L(\\theta) = P(\\mathbf{y} \\,|\\, X; \\theta) \\,. $$\n",
    "\n",
    "We want to find $\\theta_0, \\theta_1, \\ldots, \\theta_n$ that maximize the likelihood function $L(\\theta)$.  This is how we will derive the supervised learning algorithm for logistic regression.\n",
    "\n",
    "But let's take a break from this and describe an example we will work through.  This example comes from one of the programming exercises in Andrew Ng's machine learning course.  An administrator of a university department wants to determine an applicant's chance of admission based on their results from two exams.  The administrator has [data](https://github.com/marty-vanhoof/Maching_Learning/blob/master/data/logReg_data1.txt) consisting of previous applicant's exam scores and whether they were admitted to the university of not.  Let's look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "      <th>admitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.623660</td>\n",
       "      <td>78.024693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.286711</td>\n",
       "      <td>43.894998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.847409</td>\n",
       "      <td>72.902198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.182599</td>\n",
       "      <td>86.308552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.032736</td>\n",
       "      <td>75.344376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       exam1      exam2  admitted\n",
       "0  34.623660  78.024693         0\n",
       "1  30.286711  43.894998         0\n",
       "2  35.847409  72.902198         0\n",
       "3  60.182599  86.308552         1\n",
       "4  79.032736  75.344376         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# load the dataframe and display first 5 rows\n",
    "filepath = os.getcwd() + '/logReg_data1.txt'\n",
    "df = pd.read_csv(filepath, names = ['exam1', 'exam2', 'admitted'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training data has two features:  ```exam1``` and ```exam2```, and these features are both continuous variables.   The target variable is called ```admitted```, and this is a categorical variable consisting of the labels 0 or 1 (0 means that the applicant was not admitted and 1 means that the applicant was admitted).  We will use this data to build a model that estimates the probability that an applicant will be admitted to the university, given their scores on the two exams.\n",
    "\n",
    "### Boxplot\n",
    "\n",
    "Boxplots give a graphical display of five important statistics associated with any distribution:  the minimum, 25th percentile, median, 75th percentile, and maximum.  They can be very useful for comparing the distributions of continuous variables across different categories.  In this case, we are comparing the distributions of scores for ```exam1``` and ```exam2``` based on whether the applicant was admitted or not.  \n",
    "\n",
    "The boxplots below show that the distributions of exam scores for applicants who were admitted/not admitted are skewed relative to each other.  We can see that applicants who were admitted to the university have higher exam scores (on average) than those who were not admitted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAFBCAYAAACb7b3CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHAlJREFUeJzt3X+UJWV95/H3x2GUXyIzOM4ZUBzOiiwJribedZMVXREG\nE00CYZXIxs3oGRkjWTUxyYrBCJrDCR6ze9YY47GV6JyNEjALgcSsOE5gEzwG0wMmoiOQBPw5QCuD\nP0BghO/+cQtsYZzp7ul7a+7T79c5dW5Vdd2q7+3qpz+3qu59KlWFJElqy2P6LkCSJC0+A16SpAYZ\n8JIkNciAlySpQQa8JEkNMuAlSWqQAS9JUoMMeEmSGmTAS5LUoP36LmBvPPGJT6y1a9f2XYa0JN16\n663Y/qTx27p16zeqatWelpvogF+7di3T09N9lyEtSYPBwPYn9SDJl+aynKfoJUlqkAEvSVKDDHhJ\nkhpkwEuS1CADXpKkBhnwkiQ1aGQBn+RPktyR5IZZ81Ym2Zzk5u5xxayfvTnJPye5McmLRlWXJElL\nwSiP4D8E/Mwj5p0NbKmqo4Et3TRJfgx4OfDj3XP+OMmyEdYmSVLTRhbwVfW3wJ2PmH0KsKkb3wSc\nOmv+n1XVfVV1C/DPwHNGVZskSa0b9zX41VW1vRu/DVjdjR8BfGXWcl/t5kmSpAXoravaqqokNd/n\nJdkIbAQ48sgjF72uUUsysnVXzfvXKc3L1NQUU1NTAMzMzPRcjaTdGfcR/O1J1gB0j3d0878GPGXW\nck/u5j1KVU1V1aCqBqtW7bGv/X1OVc15WMjy0iht3LiR6elppqenmcT2p7ZddNFFHHfccSxbtozj\njjuOiy66qO+SejXugL8CWN+NrwcunzX/5Ukel+Qo4GjgM2OuTZI0oS666CLOOecc3v3ud3Pvvffy\n7ne/m3POOWdJh/wovyZ3EfBp4JgkX02yAbgAWJfkZuCkbpqq+jxwCfAF4OPAr1XVA6OqTZLUlvPP\nP58LL7yQE044geXLl3PCCSdw4YUXcv755/ddWm8yyad2B4NBtXy7yiSeetc+y9vFal+ybNky7r33\nXpYvX/7wvJ07d7L//vvzwANtHS8m2VpVgz0tZ092kqSJd+yxx3LNNdf80LxrrrmGY489tqeK+mfA\nS5Im3jnnnMOGDRu46qqr2LlzJ1dddRUbNmzgnHPO6bu03vT2NTlJkhbLGWecAcDrXvc6tm3bxrHH\nHsv555//8PylyICX5sF+DKR91xlnnLGkA/2RDHhpHuYTwn5IUlKfvAYvSVKDDHhJkhpkwEuSmmBX\ntT/Ma/CSpIn3UFe1F154IccffzzXXHMNGzZsAFiyH7zzCF7SkpBkZIP6Z1e1j+YRvKQlwW9AtG3b\ntm0cf/zxPzTv+OOPZ9u2bT1V1D+P4CVJE8+uah/NgJckTTy7qn00T9FLkiaeXdU+mgEvSWqCXdX+\nME/RS5LUIANekqQGGfCSJDXIgJckqUEGvCRJDTLgJUlqkAEvSVKDDHhJkhpkwEuS1CADXpKkBhnw\nkiQ1yICXJKlBvQR8kjckuSHJ55P8ejdvZZLNSW7uHlf0UZskSS0Ye8AnOQ44E3gO8Ezg55I8DTgb\n2FJVRwNbumlJkrQAfRzBHwtcW1X3VNX3gf8HnAacAmzqltkEnNpDbZIkNaGPgL8BeF6Sw5IcCLwY\neAqwuqq2d8vcBqze1ZOTbEwynWR6ZmZmPBVLAmBqaorBYMBgMMD2J+3bUlXj32iyATgLuBv4PHAf\n8MqqOnTWMjuqarfX4QeDQU1PT4+01j4loY/9o8XR+v4bDAa02v5a33eabEm2VtVgT8v18iG7qrqw\nqp5dVc8HdgA3AbcnWQPQPd7RR22SJLWgr0/RP6l7PJLh9fePAFcA67tF1gOX91GbJEkt2K+n7f6f\nJIcBO4Ffq6q7klwAXNKdvv8ScHpPtUmSNPF6Cfiqet4u5n0TOLGHciRJao492UmS1CADXpKkBhnw\nkiQ1qK8P2Un7hJUrV7Jjx46RrT/Joq9zxYoV3HnnnYu+XkltMeC1pO3YsWPiOjQZxZsGSe3xFL0k\nSQ0y4CVJapABL0lSgwx4SZIaZMBLktQgA16SpAYZ8JIkNciAlySpQXZ0swhG2RuaPaFJkhbCgF8E\nk9Ybmj2hSVL7PEUvSVKDDHhJkhpkwEuS1CADXpKkBhnwkiQ1yICXJKlBBrwkSQ0y4CVJapABL0lS\ngwx4SZIaZMBLktSgXgI+yW8k+XySG5JclGT/JCuTbE5yc/e4oo/aJElqwdgDPskRwOuBQVUdBywD\nXg6cDWypqqOBLd20JElagL5O0e8HHJBkP+BA4OvAKcCm7uebgFN7qk2SpIk39oCvqq8BfwB8GdgO\nfKuqPgGsrqrt3WK3AavHXZskSa3o4xT9CoZH60cBhwMHJXnF7GVqeHP1Xd5gPcnGJNNJpmdmZkZe\nr6QfmJqaYjAYMBgMsP1J+7Y+TtGfBNxSVTNVtRO4FPiPwO1J1gB0j3fs6slVNVVVg6oarFq1amxF\nS4KNGzcyPT3N9PQ0tj9p39ZHwH8Z+KkkByYJcCKwDbgCWN8tsx64vIfaJElqwn7j3mBVXZvkz4Hr\ngO8D1wNTwMHAJUk2AF8CTh93bZIktWLsAQ9QVecC5z5i9n0Mj+YlSfohwxO+ozH82Fd7egl4SZLm\nYz4hnKTZ0J4Pu6qVJKlBBrwkSQ0y4CVJapABL0lSgwx4SZIaZMBLktQgA16SpAYZ8JIkNciAlySp\nQQa8JEkNsqvaRVDnHgLnPaHvMuaszj2k7xIkSSNmwC+CvO3bE9XvcRLqvL6rkCSNkgGvJW3Szr6A\nZ2AkzY0BryVt0s6+gGdgJM2NH7KTJKlBBrwkSQ0y4CVJapABL0lSgwx4SZIaZMBLktQgA16SpAYZ\n8JIkNciAlySpQQa8JEkNMuAlSWqQAS9JUoPGHvBJjkny2VnDt5P8epKVSTYnubl7XDHu2iRJasXY\nA76qbqyqZ1XVs4BnA/cAlwFnA1uq6mhgSzctSZIWoO9T9CcC/1JVXwJOATZ18zcBp/ZWlSRJE67v\ngH85cFE3vrqqtnfjtwGrd/WEJBuTTCeZnpmZGUeNkjpTU1MMBgMGgwG2P2nflqrqZ8PJY4GvAz9e\nVbcnuauqDp318x1Vtdvr8IPBoKanp0dd6h4loa/f40JMWr2jNIm/i32l5sFgwL7Q/kZhX/kda2Fa\n339JtlbVYE/L9XkE/7PAdVV1ezd9e5I1AN3jHb1VJknShOsz4M/gB6fnAa4A1nfj64HLx16RJEmN\n6CXgkxwErAMunTX7AmBdkpuBk7ppSZK0APv1sdGquhs47BHzvsnwU/WSJGkv9f0pekmSNAJzDvgk\nxyd5VTe+KslRoytL0rhdc801fPCDHwRgZmaGW265peeKJO2NOQV8knOBNwFv7mYtB/50VEVJGq+3\nve1tvOMd7+D3f//3Adi5cyeveMUreq5K0t6Y6xH8LwK/ANwNUFVfBx4/qqIkjddll13GFVdcwUEH\nHQTA4Ycfzne+852eq5K0N+Ya8PfXsNeAgoc/BS+pEY997GNJQhIA7r777p4rkrS35hrwlyR5H3Bo\nkjOBTwLvH11Zksbp9NNP5zWveQ133XUX73//+znppJM488wz+y5L0l6Y09fkquoPkqwDvg0cA7y1\nqjaPtDJJY/Nbv/VbbN68mUMOOYQbb7yRt7/97axbt67vsiTthT0GfJJlwCer6gTAUJca88ADD3DS\nSSdx1VVXGepSQ/Z4ir6qHgAeTPKEMdQjacyWLVvGYx7zGL71rW/1XYqkRTTXnuy+C3wuyWa6T9ID\nVNXrR1KVpLE6+OCDecYznsG6dese/iQ9wB/+4R/2WJWkvTHXgL+UH+43XmrGQ58cnxQrVuz2LsoL\nctppp3Haaact+nol9WeuH7Lb1N2//endrBuraufoypLGY5T3jJ6ke1KvX7+e+++/n5tuugmAY445\nhuXLl/dclaS9MaeAT/ICYBNwKxDgKUnWV9Xfjq40SeNy9dVXs379etauXUtV8ZWvfIVNmzbx/Oc/\nv+/SJC3QXE/R/w/g5Kq6ESDJ0xney/3ZoypM0vj85m/+Jp/4xCc45phjALjppps444wz2Lp1a8+V\nSVqouXZ0s/yhcAeoqpsY9kcvqQE7d+58ONwBnv70p7Nzp1fhpEk21yP46SQf4Ac3mPllYHo0JUka\nt8FgwKtf/eqHbzDz4Q9/mMFg0HNVkvbGXAP+tcCvAQ99Le7vgD8eSUWSxu69730v73nPex7+Wtzz\nnvc8zjrrrJ6rkrQ35hrw+wHvqqr/CQ/3bve4kVU1gSbpq1aj+JqVJtv3v/993vCGN/DGN74RGPZu\nd9999/VclVq3cuVKduzYMZJ1j+J/8ooVK7jzzjsXfb2jMtdr8FuAA2ZNH8DwhjNi+FWrUQyjWvck\n/YFqPE488US+973vPTz9ve99j5NOOqnHirQU7NixY2T/P0cxjOrNyKjMNeD3r6rvPjTRjR84mpIk\njdu9997LwQcf/PD0wQcfzD333NNjRZL21lwD/u4kP/nQRJIB8L3dLC9pghx00EFcd911D09PT09z\nwAEH7OYZkvZ1c70G/wbgo0m+3k2vAX5pNCVJGrd3vetdvOxlL+Pwww8HYPv27Vx88cU9VyVpb8w1\n4I8CfgI4EjgN+A/AZPTBKWmPbrnlFq6//nq+/OUvc+mll3LttddO1AdHJT3aXE/R/25VfRs4FDiB\n4Vfk3juyqiSN1e/93u9xyCGHcNddd3HVVVdx1lln8drXvrbvsvZo5cqVJFn0ARjJepOwcuXKnn9r\nWirmGvAPdI8vAd5fVR8DHjuakiSN27JlywD42Mc+xplnnslLXvIS7r///p6r2rNJ+xT2JH4SW5Nr\nrgH/tSTvY3jd/a+TPG4ez5W0jzviiCN4zWtew8UXX8yLX/xi7rvvPh588MG+y5K0F+Ya0qcDVwIv\nqqq7gJXAby90o0kOTfLnSb6YZFuSn06yMsnmJDd3j/bGIo3JJZdcwote9CKuvPJKDj30UO68807e\n+c539l2WpL0w1/vB3wNcOmt6O7B9L7b7LuDjVfXS7j7zBwK/A2ypqguSnA2cDbxpL7YhaY4OPPBA\nTjvttIen16xZw5o1a3qsSNLeGvtp9iRPAJ4PXAhQVfd3ZwVOYXjPebrHU8ddmyRJrejjOvpRwAzw\nwSTXJ/lAkoOA1d2ZAYDbgNU91CZJUhP6CPj9gJ8E3ltVPwHczfB0/MNq2BH7Lr9nn2Rjkukk0zMz\nMyMvVtIPTE1NMRgMGAwG2P6kfVsfAf9V4KtVdW03/ecMA//2JGsAusc7dvXkqpqqqkFVDVatWjWW\ngiUNbdy4kenpaaanp7H9Sfu2sQd8Vd0GfCXJMd2sE4EvAFcA67t564HLx12bJEmtmGtXtYvtdcCH\nu0/Q/yvwKoZvNi5JsgH4EsOv5kmSpAXoJeCr6rPAYBc/OnHctUiS1CJ7o5MkqUEGvCRJDTLgJUlq\nkAEvSVKDDHhJkhpkwEuS1CADXpKkBhnwkiQ1yICXJKlBBrwkSQ0y4CVJapABL0lSgwx4SZIaZMBL\nktQgA16SpAYZ8JIkNciAlySpQQa8JEkNMuAlSWqQAS9JUoMMeEmSGmTAS5LUIANekqQGGfCSJDXI\ngJckqUEGvCRJDTLgJUlq0H59bDTJrcB3gAeA71fVIMlK4GJgLXArcHpV7eijPkmSJl0vAd85oaq+\nMWv6bGBLVV2Q5Oxu+k39lCZpEtS5h8B5T+i7jHmpcw/puwQtEX0G/COdArygG98EXI0BL2k38rZv\nU1V9lzEvSajz+q5CS0Ff1+AL+GSSrUk2dvNWV9X2bvw2YPWunphkY5LpJNMzMzPjqFVSZ2pqisFg\nwGAwwPYn7dvSx7vfJEdU1deSPAnYDLwOuKKqDp21zI6qWrG79QwGg5qenh5xtf1JMnFHJ/qB1vff\nYDCg7/Y3ib/jSax5ZCbs8goA532r7wpIsrWqBntarpdT9FX1te7xjiSXAc8Bbk+ypqq2J1kD3NFH\nbZKk8Zi0SyyTdnll7KfokxyU5PEPjQMnAzcAVwDru8XWA5ePuzZJklrRxxH8auCyJA9t/yNV9fEk\n/wBckmQD8CXg9B5qkySpCWMP+Kr6V+CZu5j/TeDEcdcjSVKL7MlOkqQGGfCSJDXIgJckqUEGvCRJ\nDTLgJUlqkAEvSVKDDHhJkhpkwEuS1CADXpKkBhnwkiQ1yICXJKlBBrwkSQ0y4CVJapABL0lSgwx4\nSZIaZMBLktQgA16SpAbt13cB0iRJMrLlq2q+5UjSj2TAS/NgCEuaFAa8JKk38z0r1qcVK1b0XcK8\nGPCSpF6M6oxYEs+24YfsJElqkgEvSVKDDHhJkhpkwEuS1CADXpKkBvUW8EmWJbk+yV910yuTbE5y\nc/c4Wd9HkCRpH9LnEfwbgG2zps8GtlTV0cCWblqSJC1ALwGf5MnAS4APzJp9CrCpG98EnDruusYh\nyZyHhSwvSRL019HN/wL+O/D4WfNWV9X2bvw2YPWunphkI7AR4MgjjxxljSNh5wuaZFNTU0xNTQEw\nMzPTczWSdmfsR/BJfg64o6q2/qhlapiCu0zCqpqqqkFVDVatWjWqMiXtwsaNG5menmZ6ehrbn7Rv\n6+MI/rnALyR5MbA/cEiSPwVuT7KmqrYnWQPc0UNtkiQ1YexH8FX15qp6clWtBV4O/E1VvQK4Aljf\nLbYeuHzctUmS1Ip96XvwFwDrktwMnNRNS5KkBej1bnJVdTVwdTf+TeDEPuuRJKkV+9IRvCRJWiQG\nvCRJDTLgJUlqkAEvSVKDDHhJkhpkwEuS1CADXpKkBhnwkiQ1yICXJKlBBrwkSQ3qtataSdpbSfou\nYV5WrFjRdwlaIgx4SROrqkay3iQjW7c0Lp6ilySpQQa8JEkNMuAlSWqQAS9JUoMMeEmSGmTAS5LU\nIANekqQGGfCSJDXIgJckqUEGvCRJDTLgJUlqkAEvSVKDDHhJkhpkwEuS1KCxB3yS/ZN8Jsk/Jvl8\nkrd181cm2Zzk5u7RmyZLkrRAfRzB3we8sKqeCTwL+JkkPwWcDWypqqOBLd20JElagLEHfA19t5tc\n3g0FnAJs6uZvAk4dd22SpH1TkjkPC1m+Rfv1sdEky4CtwNOA91TVtUlWV9X2bpHbgNV91CZJ2vdU\nVd8lTJxeAr6qHgCeleRQ4LIkxz3i55Vkl3szyUZgI8CRRx458lol/cDU1BRTU1MAzMzM9FzN/Mz3\nSG0+yxs+2hel7z/MJG8F7gHOBF5QVduTrAGurqpjdvfcwWBQ09PT4yhT0iMMBgNsf9L4JdlaVYM9\nLdfHp+hXdUfuJDkAWAd8EbgCWN8tth64fNy1SZLUij5O0a8BNnXX4R8DXFJVf5Xk08AlSTYAXwJO\n76E2SZKaMPaAr6p/An5iF/O/CZw47nokSWqRPdlJktQgA16SpAYZ8JIkNciAlySpQQa8JEkNMuAl\nSWqQAS9JUoN676p2bySZYdgpTqueCHyj7yK0YK3vv58Eruu7iBFpfd+1rvX999SqWrWnhSY64FuX\nZHou/Q1r3+T+m1zuu8nm/hvyFL0kSQ0y4CVJapABv2+b6rsA7RX33+Ry30029x9eg5ckqUkewUuS\n1CADXpKkBhnwjUhyWJKrknw3yR/1XY/mLsm6JFuTfK57fGHfNWnubHuTq/W2t1/fBWjR3Av8LnBc\nN2hyfAP4+ar6epLjgCuBI3quSXNn25tcTbc9j+BHLMkrknwmyWeTvC/JU5PcnOSJSR6T5O+SnNwt\n+xfdu8jPJ9k4ax3fTfLObv4nkzwnydVJ/jXJLwBU1d1VdQ3DfzZaBGPcd9dX1de7p3weOCDJ48b/\nitti25tctr1FUlUOIxqAY4G/BJZ3038M/ArwauCjwG8D75u1/Mru8QDgBuCwbrqAn+3GLwM+ASwH\nngl89hHbfCXwR32/9kkf+th33TIvBT7Z9+uf9MG2N7mDbW/xBk/Rj9aJwLOBf0gCwz/AO6rqvCQv\nA34VeNas5V+f5Be78acARwPfBO4HPt7N/xxwX1XtTPI5YO3IX8XSNPZ9l+THgXcAJ4/kFS0ttr3J\nZdtbJAb8aAXYVFVv/qGZyYHAk7vJg4HvJHkBcBLw01V1T5Krgf27ZXZW9xYTeBC4D6CqHkziPhyN\nse67JE9meJTxK1X1L6N5SUuKbW9y2fYWidfgR2sL8NIkTwJIsjLJUxm+U/ww8Fbg/d2yTwB2dH+k\n/xb4qT4K1sPGtu+SHAp8DDi7qj61WC9gibPtTS7b3iLxHegIVdUXkrwF+ESSxwA7gTcC/x54blU9\nkOQ/J3kV8BHgV5NsA24E/n6+20tyK3AI8NgkpwInV9UXFunlLClj3nf/DXga8NYkb+3mnVxVdyzK\ni1mCbHuTy7a3eOyqVpKkBnmKXpKkBhnwkiQ1yICXJKlBBrwkSQ0y4CVJapABrx8pySszz7tjJfnr\nJId2w1mz5q9N8l8WUMOHkrx0vs+TWmAb1N4w4LWoqurFVXUXcChw1qwfrQXm/c9F0vzYBvUQA34J\n29VdmJK8KslNST4DPHfWsh9K8t4kf9/djekFSf4kybYkH5q13K1JnghcAPybDO8G9c5u+nnd9G8k\nWZbhnZ7+Ick/JXlN9/wk+aMkNyb5JPCk3dT/wiR/MWt6XZLLuvGTk3w6yXVJPprk4G7+BUm+0G3z\nDxbx1ynN26S3wVnbe1vX1j6XYY9yD/VA9xfduv8+yb9b5F+f9qTvu9049Dfw6LswHQF8GVgFPBb4\nFN3dsYAPAX/GsJ/oU4BvA89g+CZxK/CsbrlbgScyPFq4Yda2XgD81azpjcBbuvHHAdPAUcBpwGZg\nGXA4cBfw0h9Rf4AvAqu66Y8AP99t/2+Bg7r5b2LYveVhDHu7eqiDp0P73gcOS3uY9DY4a3uv68bP\nAj7Qjb8bOLcbfyG7uIObw2gHj+CXttcn+UeG3Ts+BfivwNVVNVNV9wMXP2L5v6xha/0ccHtVfa6q\nHmR4H+W189z2ycCvJPkscC3D8D0aeD5wUVU9UMP7NP/Nj1pBV8v/Bl6RYZ/SPw38X4b9Uf8Y8Klu\n/euBpwLfYnjP7guTnAbcM8+apcU20W1wlku7x62z6jieYfukqv4GOCzJIfOsUXvBvuiXqOz6Lkxf\nZBiMP8p93eODs8Yfmp7v31IYvuu/8hF1vXie6/kgw3tH3wt8tKq+nyTA5qo641EbTZ7D8HaUL2XY\nD/UL57k9aVE01AZn1/XAAurQiHgEv3Tt6i5MBwD/KclhSZYDL9uL9X8HePxupq8EXttthyRPT3IQ\nw1Prv9RdH1wDnLC7jXRHGF8H3sIw7GF4NPTcJE/r1n1Qt/6DgSdU1V8DvwE8cy9en7S3mmiDu/F3\nwC93634B8I2q+vYC16UF8J3W0vVxHn0Xpu3AecCnGV53++xCV15V30zyqSQ3MDxt/jvAA93pyA8B\n72J4Ku+67oh7BjiV4X2ZXwh8geG1yE/PYXMfZngdflu37ZkkrwQuSvK4bpm3MPwHd3mS/Rkevbxx\noa9PWgQttcFdOQ/4kyT/xPBy2PqFvhYtjHeT08TL8HvC11fVhX3XIkn7CgNeEy3JVuBuYF1V3ben\n5SVpqfAUvSZC9/32ox4x+01V9ew+6pGWmt20wSt3tbz65xG8JEkN8lP0kiQ1yICXJKlBBrwkSQ0y\n4CVJapABL0lSg/4/9FmCSNP1lS8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111fb7f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split the data into 'admitted_yes', 'admitted_no'\n",
    "admitted_yes = df[ df.admitted == 1 ]\n",
    "admitted_no = df[ df.admitted == 0 ]\n",
    "data = [admitted_yes, admitted_no]\n",
    "xlabels = ['admitted_yes', 'admitted_no']\n",
    "\n",
    "# make the plot\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (8, 5), sharey = True)\n",
    "fig.subplots_adjust(wspace = 0)\n",
    "for i in range(0,2):\n",
    "    ax[i].boxplot( [data[i].exam1, data[i].exam2], widths = [0.4, 0.4] )\n",
    "    ax[i].set( xticklabels = ['exam1', 'exam2'], xlabel = xlabels[i], ylabel = 'score' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Scatterplot\n",
    "\n",
    "The scatterplot below seems to suggest that if some function of the exam scores is above a certain threshold, then the applicant will be admitted.  We would like to trace out a boundary between the two classes that will classify the data into 'admitted_yes' or 'admitted_no'.  This boundary is called a **decision boundary**, and logistic regression will help us find the decision boundary and make class predictions.  We haven't found the decision boundary yet, so in the code below, we set decision_boundary to False.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAFACAYAAAD07atFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113af5748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def scatterplot(decision_boundary = False):\n",
    "    '''Plot the training data using a scatterplot.  \n",
    "    If decision_boundary is set to True, then plot the boundary.\n",
    "    Note that the theta parameters are not actually defined yet.'''\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8,5))\n",
    "    \n",
    "    if decision_boundary:\n",
    "        # plot the decision boundary\n",
    "        x1 = np.linspace(df.exam1.min(), df.exam1.max(), 50)\n",
    "        x2 = (-theta_1/theta_2)*x1 - (theta_0/theta_1)\n",
    "        plt.plot(x1, x2, color = 'black', label = 'decision boundary')\n",
    "\n",
    "    # plot the training data\n",
    "    plt.scatter(admitted_yes.exam1, admitted_yes.exam2, color = 'blue', label = 'admitted_yes')\n",
    "    plt.scatter(admitted_no.exam1, admitted_no.exam2, color = 'red', label = 'admitted_no')\n",
    "    plt.xlabel('exam1')\n",
    "    plt.ylabel('exam2')\n",
    "    #plt.xlim(25,100)\n",
    "    #plt.ylim(25,100)\n",
    "    plt.legend(bbox_to_anchor = (1,0.85), loc = 3)\n",
    "    plt.show()\n",
    "    \n",
    "scatterplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Cost Function for Logistic Regression\n",
    "\n",
    "Our goal is to find an algorithm that will learn the parameters $\\theta = (\\theta_0, \\theta_1, \\ldots, \\theta_n)^T$ in order to maximize the likelihood function\n",
    "\n",
    "$$ L(\\theta) = P(\\mathbf{y} \\,|\\, X; \\theta) $$\n",
    "\n",
    "Let's assume that our $m$ training examples are *independent*, so that\n",
    "\n",
    "\\begin{align*} \n",
    "P(\\mathbf{y} \\,|\\, X; \\theta) &= \\prod_{i=1}^m P(y_i \\,|\\, \\mathbf{x}_i; \\theta) \\\\\n",
    "                              &= \\prod_{i=1}^m h_\\theta(\\mathbf{x}_i)^{y_i} (1 - h_\\theta(\\mathbf{x}_i))^{1 - y_i} \n",
    "\\end{align*}\n",
    "\n",
    "where the first equality is because of the independence assumption and the last equality is due to $(1)$ above.  In practice, it is easier to maximize the **log-likelihood** $\\ell(\\theta)$, which is the natural logarithm of the likelihood function\n",
    "\n",
    "\\begin{align*}\n",
    "\\ell(\\theta) &= \\ln L(\\theta) \\\\\n",
    "&= \\ln \\bigg[ \\prod_{i=1}^m h_\\theta(\\mathbf{x}_i)^{y_i} (1 - h_\\theta(\\mathbf{x}_i))^{1 - y_i} \\bigg] \\\\ \n",
    "&= \\sum_{i=1}^m y_i \\ln h_\\theta(\\mathbf{x}_i) + (1 - y_i) \\ln(1 - h_\\theta(\\mathbf{x}_i)) \\,. \n",
    "\\end{align*}\n",
    "\n",
    "Since the logarithm function is increasing, maximizing $L(\\theta)$ is equivalent to maximizing $\\ell(\\theta) = \\ln L(\\theta)$.  Also note that maximizing $\\ell(\\theta)$ is equivalent to minimizing $- \\ell(\\theta)$.  The reason we want to minimize $- \\ell(\\theta)$ is because we can use the gradient descent algorithm again.  Recall that in [linear regression](https://github.com/marty-vanhoof/Maching_Learning/blob/master/Linear_Regression/Linear_Regression.ipynb), we used gradient descent to minimize a certain cost function $J(\\theta)$.  In the case of logistic regression, we use the negative log-likelihood as our cost function, so we want to minimize\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m - y_i \\ln h_\\theta(\\mathbf{x}_i) - (1 - y_i) \\ln (1 - h_\\theta(\\mathbf{x}_i)) \\,. $$ \n",
    "\n",
    "It turns out that this function is convex (here is a [proof](http://mathgotchas.blogspot.ca/2011/10/why-is-error-function-minimized-in.html)), so the gradient descent algorithm will eventually converge to the global minimum of $J(\\theta)$ with a suitable learning rate $\\alpha$.  Let's write this cost function in Python using numpy matrix operations.\n",
    "\n",
    "Recall that $h_\\theta(\\mathbf{x}_i) = g(\\theta^T \\mathbf{x}_i)$, where $g$ is the logistic function.  Let $\\mathbf{1}, \\mathbf{ln}_h$ and $\\mathbf{ln}_{1-h}$ be the (m x 1) column vectors defined as follows:\n",
    "\n",
    "$$\n",
    "\\mathbf{1} =\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "\\vdots \\\\\n",
    "1\n",
    "\\end{bmatrix} \\, , \\quad\n",
    "\\mathbf{ln}_h =\n",
    "\\begin{bmatrix}\n",
    "\\ln h_\\theta(\\mathbf{x}_1) \\\\\n",
    "\\ln h_\\theta(\\mathbf{x}_2) \\\\\n",
    "\\vdots \\\\ \n",
    "\\ln h_\\theta(\\mathbf{x}_m)\n",
    "\\end{bmatrix} \\, , \\quad\n",
    "\\mathbf{ln}_{1-h} =\n",
    "\\begin{bmatrix}\n",
    "\\ln (1 - h_\\theta(\\mathbf{x}_1)) \\\\\n",
    "\\ln (1 - h_\\theta(\\mathbf{x}_2)) \\\\\n",
    "\\vdots \\\\ \n",
    "\\ln (1 - h_\\theta(\\mathbf{x}_m)) \n",
    "\\end{bmatrix} \\,. \n",
    "$$\n",
    "\n",
    "Then in matrix form, the cost function can be written as\n",
    "\n",
    "$$ J(\\theta) = -\\frac{1}{m} \\big[\\, \\mathbf{y}^T \\mathbf{ln}_h + (\\mathbf{1} - \\mathbf{y})^T \\mathbf{ln}_{1 - h} \\,\\big] \\,. $$\n",
    "\n",
    "We can implement this very easily with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logReg_cost(theta, X, y):\n",
    "    '''Compute the cost function. \n",
    "    Inputs:\n",
    "    X is an m by (n+1) numpy array, where m = # of training examples\n",
    "                                     n = # of features (excluding the \"1\" column)\n",
    "    y is an m by 1 numpy array\n",
    "    theta is a 1 by (n+1) numpy array'''\n",
    "    \n",
    "    # first transform the inputs to numpy matrices\n",
    "    X, y, theta = np.matrix(X), np.matrix(y), np.matrix(theta)\n",
    "    \n",
    "    ln_h = np.log( logistic(X*theta.T) )\n",
    "    ln_1h = np.log( 1 - logistic(X*theta.T) ) \n",
    "    J_theta = ( -1/len(y) )*( y.T*ln_h + (1 - y.T)*ln_1h )\n",
    "    \n",
    "    return J_theta[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in our example, the training data consists of exam scores (```exam1```, ```exam2```) for students who applied to a university, along with a column called ```admitted``` that contains information about whether each student was admitted to the university or not.  This column consists of the labels 1 or 0 (1 if the students was admitted, 0 otherwise). \n",
    "\n",
    "Let's compute the cost function on our dataset with $\\theta$ initialized to all zeros:  $\\, \\theta = (0,0,0)$.  The feature matrix $X$ will consist of the two columns ```exam1``` and ```exam2``` (plus a column of ones by convention).  The target vector $\\mathbf{y}$ will consist of the class labels for each training example, so $\\mathbf{y}$ is just the ```admitted``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ones</th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "      <th>admitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>34.623660</td>\n",
       "      <td>78.024693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30.286711</td>\n",
       "      <td>43.894998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>35.847409</td>\n",
       "      <td>72.902198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>60.182599</td>\n",
       "      <td>86.308552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>79.032736</td>\n",
       "      <td>75.344376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ones      exam1      exam2  admitted\n",
       "0     1  34.623660  78.024693         0\n",
       "1     1  30.286711  43.894998         0\n",
       "2     1  35.847409  72.902198         0\n",
       "3     1  60.182599  86.308552         1\n",
       "4     1  79.032736  75.344376         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert column of ones and look a first 5 rows\n",
    "df.insert(0, 'ones', 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost with initial theta:  0.69314718056\n"
     ]
    }
   ],
   "source": [
    "# get the feature matrix X, target vector y, and initialize theta to (0,0,0)\n",
    "X = df.iloc[:, 0:3].values\n",
    "y = df.iloc[:, 3:4].values\n",
    "theta = np.zeros(3)#.reshape((1,3))\n",
    "\n",
    "# compute the cost function with initial theta\n",
    "print('cost with initial theta: ', logReg_cost(theta, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "We are trying to minimize the cost function\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m - y_i \\ln h_\\theta(\\mathbf{x}_i) - (1 - y_i) \\ln (1 - h_\\theta(\\mathbf{x}_i)) \\,. $$ \n",
    "\n",
    "Since $J(\\theta)$ is a convex function with a global minimum, we can use gradient descent to find this minimum value.  The graph of $J(\\theta)$ is a 3-dimensional manifold in $\\mathbb{R}^4$.  If we start at any point on the manifold, then the negative gradient points in the direction of steepest descent.  The gradient descent algorithm will follow the negative gradient on each iteration, and given a suitable learning rate $\\alpha$ (which controls the size of each step), the algorithm will eventually converge to this global minimum point.\n",
    "\n",
    "Recall from multivariable calculus that the gradient, $\\nabla J$, of the function $J: \\mathbb{R}^{n+1} \\rightarrow \\mathbb{R}$ is computed as the vector of partial derivatives\n",
    "\n",
    "$$\n",
    "\\nabla J =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial J}{\\partial \\theta_0} \\\\\n",
    "\\frac{\\partial J}{\\partial \\theta_1} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial J}{\\partial \\theta_n}\n",
    "\\end{bmatrix} \\,.\n",
    "$$\n",
    "\n",
    "Each iteration of the gradient descent algorithm will update the parameter vector $\\theta$ according to the rule\n",
    "\n",
    "$$ \\theta := \\theta - \\alpha \\nabla J(\\theta) \\,, $$\n",
    "\n",
    "So for $j = 0, \\ldots, n$, each coordinate of $\\theta$ will be updated as\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta) \\, \\qquad (2) $$\n",
    "\n",
    "We will compute the partial derivative of $J(\\theta)$ with respect to $\\theta_j$.  As a first step, it's not hard to verify that the derivative of the logistic function is given as follows\n",
    "\n",
    "$$ g'(z) = g(z)(1 - g(z)) \\,. $$\n",
    "\n",
    "So if $z = \\theta_0 + \\theta_1 x_{i1} + \\ldots + \\theta_n x_{in} = \\theta^T \\mathbf{x}_i$, then by the chain rule we get\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta_j} g(\\theta^T \\mathbf{x}_i) &= g(\\theta^T \\mathbf{x}_i)(1 - g(\\theta^T \\mathbf{x}_i)) \n",
    "\\frac{\\partial}{\\partial \\theta_j} \\theta^T \\mathbf{x}_i \\\\ \n",
    "                                                            &= g(\\theta^T \\mathbf{x}_i)(1 - g(\\theta^T \\mathbf{x}_i)) \\, x_{ij}  \n",
    "\\end{align*}\n",
    "\n",
    "Therefore, we have\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta_j} J(\\theta) &= \\frac{\\partial}{\\partial \\theta_j} \\bigg[ \\frac{1}{m} \\sum_{i=1}^m - y_i \\ln g(\\theta^T \\mathbf{x}_i) - (1 - y_i) \\ln (1 - g(\\theta^T \\mathbf{x}_i)) \\bigg] \\\\\n",
    "                                             &= -\\frac{1}{m} \\sum_{i=1}^m \\bigg[ \\frac{y_i}{g(\\theta^T \\mathbf{x}_i)} - \\frac{1 - y_i}{1 - g(\\theta^T \\mathbf{x}_i)} \\bigg] \\frac{\\partial}{\\partial \\theta_j} g(\\theta^T \\mathbf{x}_i) \\\\\n",
    "                                             &= -\\frac{1}{m} \\sum_{i=1}^m \\bigg[ \\frac{y_i}{g(\\theta^T \\mathbf{x}_i)} - \\frac{1 - y_i}{1 - g(\\theta^T \\mathbf{x}_i)} \\bigg] g(\\theta^T \\mathbf{x}_i)(1 - g(\\theta^T \\mathbf{x}_i)) \\, x_{ij} \\\\\n",
    "                                             &= -\\frac{1}{m} \\sum_{i=1}^m \\big( y_i (1 - g(\\theta^T \\mathbf{x}_i)) - (1 - y_i) g(\\theta^T \\mathbf{x}_i) \\big) \\, x_{ij} \\\\\n",
    "                                             &= -\\frac{1}{m} \\sum_{i=1}^m (y_i - g(\\theta^T \\mathbf{x}_i)) \\, x_{ij}\\\\\n",
    "                                             &= \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(\\mathbf{x}_i) - y_i) \\, x_{ij}\n",
    "\\end{align*}\n",
    "\n",
    "so the update rule $(2)$ becomes\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\frac{\\alpha}{m} \\sum_{i=1}^m (h_\\theta(\\mathbf{x}_i) - y_i) \\, x_{ij} \\quad \\textrm{for all } \\, j = 0, \\ldots, n $$\n",
    "\n",
    "and we should repeat this until the algorithm coverges.  \n",
    "\n",
    "Now let's implement the gradient computation with a Python function.  Our function will compute the gradient vector, but not actually implement gradient descent.  Then we will use the [scipy.optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html#module-scipy.optimize) module to find the optimal value of $\\theta$.  The gradient, $\\nabla J(\\theta)$, is the vector whose $j^{th}$ entry is given by\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\theta_j} J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(\\mathbf{x}_i) - y_i) \\, x_{ij} \\,. $$\n",
    "\n",
    "Let $\\mathbf{h}_\\theta$ be the column vector consisting of the entries $h_\\theta(\\mathbf{x}_i)$ for $i = 1, \\ldots, m$\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_\\theta =\n",
    "\\begin{bmatrix}\n",
    "h_\\theta(\\mathbf{x}_1) \\\\\n",
    "h_\\theta(\\mathbf{x}_2) \\\\\n",
    "\\vdots \\\\\n",
    "h_\\theta(\\mathbf{x}_m)\n",
    "\\end{bmatrix} \\,. \n",
    "$$\n",
    "\n",
    "The gradient can now be written as\n",
    "\n",
    "$$ \\nabla J(\\theta) = \\frac{1}{m} (\\, \\mathbf{h}_\\theta - \\mathbf{y} \\,)^T X \\,, $$\n",
    "\n",
    "so we can implement this using numpy matrix operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logReg_gradient(theta, X, y):\n",
    "    '''Compute the gradient of the logistic regression cost function. \n",
    "    Inputs:\n",
    "    X is an m by (n+1) numpy array, where m = # of training examples\n",
    "                                     n = # of features (excluding the \"1\" column)\n",
    "    y is an m by 1 numpy array\n",
    "    theta is a 1 by (n+1) numpy array\n",
    "    Output:\n",
    "    1 by (n+1) numpy array of partial derivatives'''\n",
    "    \n",
    "    # transform the inputs to numpy matrices\n",
    "    X, y, theta = np.matrix(X), np.matrix(y), np.matrix(theta)\n",
    "    \n",
    "    h_theta = logistic(X*theta.T)\n",
    "    gradient = ( 1 / len(y) )*(h_theta - y).T * X\n",
    "    return np.array(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -0.1        -12.00921659 -11.26284221]]\n"
     ]
    }
   ],
   "source": [
    "grad = logReg_gradient(theta, X, y)\n",
    "print( grad )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SciPy to Optimize the Parameters\n",
    "\n",
    "Instead of implementing the gradient descent algorithm ourselves ( which would require experimentation to find a suitable learning rate $\\alpha$ ), we will use Python's SciPy library to find the optimal $\\theta$ parameters.  SciPy is a very powerful libary used for scientific and technical computing, and within SciPy there a module called [optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html) that has a large number of tools for performing mathematical optimization.  One of these tools is a function called [fmin_tnc](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_tnc.html#scipy.optimize.fmin_tnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_tnc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be passing this function 4 parameters:\n",
    "\n",
    "```\n",
    "fmin_tnc(func, x0, fprime, args)\n",
    "```\n",
    "\n",
    "- ```func``` is the function we want to minimize.  In our case, this is the function ```logReg_cost``` that we wrote above.\n",
    "- ```x0``` is our starting value or initial estimate, which is $\\theta = (0,0,0)$.\n",
    "- ```fprime``` is the gradient of ```logReg_cost``` ( the gradient of $J(\\theta)$ ).\n",
    "- ```args``` are the arguments to pass to the function, so ```args``` = $(X,y)$.\n",
    "\n",
    "The function will return an array of fitted parameters, the number of function evaluations, along with a return code. The return code 0 below means that the algorithm has found the minimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of fmin_tnc:  (array([-25.16131861,   0.20623159,   0.20147149]), 36, 0) \n",
      "\n",
      "theta_fit =  [-25.16131861   0.20623159   0.20147149] \n",
      "\n",
      "theta_fit components:  -25.1613186128 0.206231588655 0.201471485896\n"
     ]
    }
   ],
   "source": [
    "# run fmin_tnc() and get the theta_fit parameters\n",
    "result = fmin_tnc( func=logReg_cost, x0=theta, fprime=logReg_gradient, args=(X,y) )\n",
    "theta_fit = result[0]\n",
    "theta_0 = theta_fit[0]\n",
    "theta_1 = theta_fit[1]\n",
    "theta_2 = theta_fit[2]\n",
    "\n",
    "print( 'result of fmin_tnc: ', result, '\\n')\n",
    "print( 'theta_fit = ', theta_fit, '\\n' )\n",
    "print( 'theta_fit components: ', theta_0, theta_1, theta_2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Probabilities / Making Predictions\n",
    "\n",
    "The parameters returned by the optimization algorithm are $\\theta_0 = -25.16$, $\\theta_1 = 0.2062$, and $\\theta_2 = 0.2015$ ( rounded to 4 significant figures ).  Now we can use these to estimate the probability of admission based on an applicant's scores on the two exams.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_probability(exam1, exam2):\n",
    "    '''Estimate the probability of admission based on the scores of\n",
    "    exam1 and exam2'''\n",
    "    \n",
    "    z = theta_0 + theta_1*exam1 + theta_2*exam2\n",
    "    return logistic(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, based on our model, for an applicant who scored 45 on Exam 1 and 85 on Exam 2, their admission probability is about 78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7762906228256099"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_probability(45, 85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the logistic model to predict binary outcomes by specifying a probability threshold.  For example we can predict that a student will be admitted (class label 1) if their admission probability is at least 50%.  Similarly, we can predict that a student will not be admitted (class label 0) if their admission probability is less than 50%.  Then we can evaluate how our model performs on the training data.  In doing this, we will actually be committing one of the cardinal sins of machine learning:  Not splitting our data into separate training and test sets.  This can lead to something called **overfitting**, where our model performs well on the training data, but does poorly on new unseen data.\n",
    "\n",
    "But for now, let's just see how we can make predictions and evaluate the accuracy of our model on the training data.  The **accuracy** is defined as the number of correct predictions divided by the total number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    '''Make predictions for each training example in X.\n",
    "    Predict 1 if probability >= 0.5 and 0 otherwise.\n",
    "    Returns an array of m predictions.'''\n",
    "    \n",
    "    theta, X = np.matrix(theta), np.matrix(X)\n",
    "    probs = logistic(X * theta.T)\n",
    "    predictions = ( probs >= 0.5 ).astype(int)\n",
    "    return np.array(predictions)\n",
    "\n",
    "def accuracy(predictions, y):\n",
    "    '''Compute the accuracy of the model by comparing the\n",
    "    array of predictions to the target vector y.\n",
    "    Returns the proportion of correct predictions.'''\n",
    "    \n",
    "    correct = (predictions == y).astype(int)\n",
    "    accuracy = sum(correct) / len(predictions)\n",
    "    return accuracy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 89.0%\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(theta_fit, X)\n",
    "accuracy_percent = accuracy(predictions, y) * 100\n",
    "print( 'accuracy: {}%'.format(accuracy_percent) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this means is that on the training set, the percentage of correct predictions is 89%.  This seems pretty nice, but is misleading because we didn't test our model on new unseen data.  So the accuracy we computed is probably higher than it's true performance.  We will discuss this issue in more detail in a later article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Decision Boundary\n",
    "\n",
    "Let's plot the decision boundary for the scatterplot that we made above.  This decision boundary will be based on the fitted $\\theta$ parameters that we got as the output from our logistic regression model.  The boundary will be a line separating the applicants who were not admitted from the applicants who were admitted to the university.  To do this, we need a binary prediction (not a probability), so we will use the same probability threshold as above, which means that if an applicant has an admission probability of at least 0.5, then we will classify them as admitted, and if their admission probability is less than 0.5, then we will classify them as not admitted.\n",
    "\n",
    "Note that\n",
    "\n",
    "\\begin{align*}\n",
    "h_\\theta(\\mathbf{x}) = \\frac{1}{1 + e^{-\\theta^T \\mathbf{x}}} = 0.5 &\\Longleftrightarrow e^{-\\theta^T \\mathbf{x}} = 1 \\\\\n",
    "                                                                    &\\Longleftrightarrow \\theta^T \\mathbf{x} = 0 \\\\\n",
    "                                                                    &\\Longleftrightarrow \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 = 0 \\\\\n",
    "                                                                    &\\Longleftrightarrow x_2 = -\\frac{\\theta_1}{\\theta_2} x_1 - \\frac{\\theta_0}{\\theta_1}\n",
    "\\end{align*}\n",
    "\n",
    "so this line will be our decision boundary.  Here, $x_1, x_2$ are variables representing the scores on exam1 and exam2 respectively, and $\\theta_0, \\theta_1, \\theta_2$ were found above by the optimization algorithm.  As a reminder, the fitted $\\theta$ parameters are given as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_0 =  -25.1613186128\n",
      "theta_1 =  0.206231588655\n",
      "theta_2 =  0.201471485896\n"
     ]
    }
   ],
   "source": [
    "print( 'theta_0 = ', theta_0 )\n",
    "print( 'theta_1 = ', theta_1 )\n",
    "print( 'theta_2 = ', theta_2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and here is the scatterplot with the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnkAAAFLCAYAAACqU5qaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d3b9400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatterplot(decision_boundary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
