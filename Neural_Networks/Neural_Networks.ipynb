{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [The Neural Network Model](#nn_model)\n",
    "- [The Dataset](#dataset)\n",
    "- [Forward Propogation](#forward_prop)\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "...\n",
    "\n",
    "<a id='nn_model'></a>\n",
    "### The Neural Network Model\n",
    "\n",
    "...\n",
    "\n",
    "<a id='dataset'></a>\n",
    "### The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dimensions:  (5000, 400)\n",
      "y dimensions:  (5000, 1)\n",
      "theta1 dimensions:  (25, 401)\n",
      "theta2 dimensions:  (10, 26)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt  \n",
    "from scipy.io import loadmat  \n",
    "%matplotlib inline\n",
    "\n",
    "# load the datasets\n",
    "data = loadmat('NNdata1.mat')\n",
    "data2 = loadmat('NNweights.mat')\n",
    "# X is the feature matrix, y is the vector of class labels\n",
    "X, y = data['X'], data['y']\n",
    "# get the intial theta1 and theta2 parameters\n",
    "theta1, theta2 = data2['Theta1'], data2['Theta2']\n",
    "print('X dimensions: ', X.shape)\n",
    "print('y dimensions: ', y.shape)\n",
    "print('theta1 dimensions: ', theta1.shape)\n",
    "print('theta2 dimensions: ', theta2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label [10] is transformed to [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "Label [1] is transformed to [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Label [2] is transformed to [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Label [3] is transformed to [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Label [4] is transformed to [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "Label [5] is transformed to [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "Label [6] is transformed to [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "Label [7] is transformed to [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "Label [8] is transformed to [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "Label [9] is transformed to [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "\n",
      "y_new dimensions:  (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "# transform each label i from 1,2,...,10 into a 10-dimensional vector with \n",
    "# a 1 at the ith index and 0s elsewhere\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "y_new = enc.fit_transform(y)\n",
    "\n",
    "for i in range(0, 5000, 500):\n",
    "    print( 'Label {} is transformed to {}'.format(y[i], y_new[i,:]) )\n",
    "\n",
    "print('\\ny_new dimensions: ', y_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='forward_prop'></a>\n",
    "### Forward Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " array([[ -2.93684669,  -2.45058587,   4.95510333, ...,   3.56635593,\n",
       "           2.81388641,  -2.1195223 ],\n",
       "        [ -4.81302157,  -2.92257775,   2.6445065 , ...,   2.10497303,\n",
       "           4.69948787,  -2.76096862],\n",
       "        [ -4.24056958,  -3.68698052,   5.99656398, ...,   1.54599347,\n",
       "           3.08971226,  -2.32990819],\n",
       "        ..., \n",
       "        [ -0.86267303,   1.00939507,  -1.67526051, ...,   1.8185898 ,\n",
       "          -3.18203449,  -1.72539781],\n",
       "        [  1.74408423,  -0.58216518,  -1.49164167, ...,   4.17481481,\n",
       "          -0.96739536,  -3.08906563],\n",
       "        [  3.55683614, -12.11330792,   5.01096205, ...,   7.17585008,\n",
       "           2.15484114,  -2.9424052 ]]),\n",
       " array([[  1.00000000e+00,   5.03618685e-02,   7.93957162e-02, ...,\n",
       "           9.72517962e-01,   9.43421623e-01,   1.07213787e-01],\n",
       "        [  1.00000000e+00,   8.05782163e-03,   5.10486829e-02, ...,\n",
       "           8.91385592e-01,   9.90982126e-01,   5.94701645e-02],\n",
       "        [  1.00000000e+00,   1.41949887e-02,   2.44354705e-02, ...,\n",
       "           8.24334311e-01,   9.56466386e-01,   8.86760824e-02],\n",
       "        ..., \n",
       "        [  1.00000000e+00,   2.96781175e-01,   7.32901746e-01, ...,\n",
       "           8.60396828e-01,   3.98474223e-02,   1.51177198e-01],\n",
       "        [  1.00000000e+00,   8.51205095e-01,   3.58434539e-01, ...,\n",
       "           9.84854863e-01,   2.75399966e-01,   4.35605471e-02],\n",
       "        [  1.00000000e+00,   9.72262381e-01,   5.48598771e-06, ...,\n",
       "           9.99235749e-01,   8.96120297e-01,   5.00966928e-02]]),\n",
       " array([[ -9.09100987,  -6.35139284,  -5.97820432, ...,  -7.81998092,\n",
       "          -5.03242138,   5.45280636],\n",
       "        [ -7.64327488,  -6.02365485,  -5.66663594, ...,  -6.03362019,\n",
       "          -6.22762221,   5.44411453],\n",
       "        [ -9.33162618,  -5.72811111,  -3.64155808, ...,  -2.71165297,\n",
       "          -5.19785122,   2.55649129],\n",
       "        ..., \n",
       "        [ -2.90790484,  -5.5644267 ,  -3.48889874, ...,  -6.13702924,\n",
       "           0.61827864, -10.62754533],\n",
       "        [ -7.09249356,  -7.3819422 ,  -8.06415305, ...,  -4.41613593,\n",
       "           3.52570957,  -8.4865856 ],\n",
       "        [ -9.94121247,  -7.68638967, -10.74675633, ...,  -5.15553077,\n",
       "           0.82968816,  -2.41737004]]),\n",
       " array([[  1.12661530e-04,   1.74127856e-03,   2.52696959e-03, ...,\n",
       "           4.01468105e-04,   6.48072305e-03,   9.95734012e-01],\n",
       "        [  4.79026796e-04,   2.41495958e-03,   3.44755685e-03, ...,\n",
       "           2.39107046e-03,   1.97025086e-03,   9.95696931e-01],\n",
       "        [  8.85702310e-05,   3.24266731e-03,   2.55419797e-02, ...,\n",
       "           6.22892325e-02,   5.49803551e-03,   9.28008397e-01],\n",
       "        ..., \n",
       "        [  5.17641791e-02,   3.81715020e-03,   2.96297510e-02, ...,\n",
       "           2.15667361e-03,   6.49826950e-01,   2.42384687e-05],\n",
       "        [  8.30631310e-04,   6.22003774e-04,   3.14518512e-04, ...,\n",
       "           1.19366192e-02,   9.71410499e-01,   2.06173648e-04],\n",
       "        [  4.81465717e-05,   4.58821829e-04,   2.15146201e-05, ...,\n",
       "           5.73434571e-03,   6.96288990e-01,   8.18576980e-02]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logistic(z):\n",
    "    \n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def forward_propagate(X, theta1, theta2):\n",
    "    '''\n",
    "    Implements the forward propogation algorithm.\n",
    "    Inputs:\n",
    "    - X is an m by (n+1) numpy array where m = # of training examples\n",
    "                                           n = # of features\n",
    "    - theta1 is a p by (m+1) numpy array representing the matrix of\n",
    "      parameters mapping the input layer to the hidden layer.  \n",
    "      Note that p = # of units in the hidden layer\n",
    "    - theta2 is a k by (p+1) numpy array mapping the hidden layer to\n",
    "      the output layer, where k = # of output units\n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    # insert column of ones into X\n",
    "    X = np.insert(X, 0, np.ones(m), axis=1)\n",
    "    \n",
    "    # Note:  '@' allows us to multiply numpy arrays like matrices\n",
    "    Z2 = X @ theta1.T\n",
    "    A2 = logistic(Z2)\n",
    "    # insert column of ones into A2\n",
    "    A2 = np.insert(A2, 0, np.ones(m), axis=1)\n",
    "    Z3 = A2 @ theta2.T\n",
    "    \n",
    "    return X, Z2, A2, Z3, logistic(Z3)\n",
    "\n",
    "forward_propagate(X, theta1, theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
