{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "We can think of linear regression as the \"grandfather\" of supervised machine learning.  It developed as an important technique in statistics long before machine learning existed as a field in its own right.  The idea in supervised learning is that we have a data set called the **training data**.  The training data consists of a set of pairs $\\{ \\, ( \\mathbf{x}_1,y_1 ), ( \\mathbf{x}_2,y_2 ) \\ldots,  ( \\mathbf{x}_m,y_m ) \\, \\}$, where each input variable $\\mathbf{x}_i$ is a vector called a **feature vector**, and the output variables $y_i$ (usually real numbers) are the corresponding **labels**.  \n",
    "\n",
    "If $\\mathcal{X}$ is the input space and $\\mathcal{Y}$ is the output space, then the objective of a supervised learning algorithm is to \"learn\" a function $h: \\mathcal{X} \\rightarrow \\mathcal{Y}$ that approximates the training data and will generalize in order to predict the output for new instances.  When the target space $\\mathcal{Y}$ consists of continuous data, then the learning problem is called a **regression** problem.  When the target space $\\mathcal{Y}$ consists of discrete data, then the learning problem is called a **classification** problem.\n",
    "\n",
    "### Simple Linear Regression\n",
    "\n",
    "In simple linear regression, we have $\\mathcal{X} = \\mathcal{Y} = \\mathbb{R}$, so that $h: \\mathbb{R} \\rightarrow \\mathbb{R}$ is a function from the real numbers to the real numbers, and $h$ is a linear function of the form $h_{\\theta}(x) = \\theta_0 + \\theta_1 x$, where $\\theta_1, \\theta_2$ are called the **weights**.  The training data will then consist of a bunch of points in the plane, and we are trying the find a line that \"best fits\" the data.  This line is called the **least squares line**  (image from [wikipedia](https://en.wikipedia.org/wiki/Linear_regression))\n",
    "\n",
    "<br/>\n",
    "<img src=\"least_squares_line.png\">\n",
    "<br/>\n",
    "\n",
    "Now let's look at an example.  This example comes from one of the programming exercises in Andrew Ng's machine learning course.  Suppose you are the CEO of a food truck franchise and you are considering different cities where you can expand your business.  Your chain already has trucks in a number of cities and you have [data](https://github.com/marty-vanhoof/Maching_Learning/blob/master/data/ex1data1.txt) about the population of each city and the profit of the corresponding food truck.  You would like to estimate the expected profit of a new food truck given only the population of a city (admittedly this example is a little simplistic, but it's good for illustrating the main ideas in linear regression).\n",
    "\n",
    "We will use Pandas to analyze the data.  First we import the modules that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's load the dataframe and take a look at the first 5 rows.  The population and profit columns are in units of $10000, so to get the actual numbers just multiply by 10000.  We can also use Panda's ```describe()``` function to get some statistics about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1101</td>\n",
       "      <td>17.5920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5277</td>\n",
       "      <td>9.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.5186</td>\n",
       "      <td>13.6620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0032</td>\n",
       "      <td>11.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8598</td>\n",
       "      <td>6.8233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   population   profit\n",
       "0      6.1101  17.5920\n",
       "1      5.5277   9.1302\n",
       "2      8.5186  13.6620\n",
       "3      7.0032  11.8540\n",
       "4      5.8598   6.8233"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = os.getcwd() + '/ex1data1.txt'\n",
    "df = pd.read_csv(filepath, names = ['population', 'profit'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.0000</td>\n",
       "      <td>97.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.1598</td>\n",
       "      <td>5.8391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.8699</td>\n",
       "      <td>5.5103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.0269</td>\n",
       "      <td>-2.6807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.7077</td>\n",
       "      <td>1.9869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.5894</td>\n",
       "      <td>4.5623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.5781</td>\n",
       "      <td>7.0467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.2030</td>\n",
       "      <td>24.1470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       population   profit\n",
       "count     97.0000  97.0000\n",
       "mean       8.1598   5.8391\n",
       "std        3.8699   5.5103\n",
       "min        5.0269  -2.6807\n",
       "25%        5.7077   1.9869\n",
       "50%        6.5894   4.5623\n",
       "75%        8.5781   7.0467\n",
       "max       22.2030  24.1470"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get some basic statistics\n",
    "df.describe().apply(lambda x: x.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scatterplot of the data suggests a positive correlation between population and profit, and many of the data points cluster around cities with lower populations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119cb5b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a scatterplot of the data\n",
    "plt.scatter(df.population, df.profit)\n",
    "plt.xlabel('population')\n",
    "plt.ylabel('profit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Gradient Descent Algorithm\n",
    "\n",
    "Let's write the feature vector $\\mathbf{x}_i$ as a row vector $\\mathbf{x}_i = (x_{i0}, x_{i1}, \\dots, x_{in})$ where $i$ runs from 1 to $m$, so that $n$ is the dimension of the feature space $\\mathcal{X}$ and $m$ is the number of training examples.  We want an algorithm that will find the parameters $\\theta_0, \\theta_1, \\ldots, \\theta_n$ so that the function $h_\\theta(\\mathbf{x}_i) = \\theta_0 x_{i0} + \\theta_2 x_{i1} + \\ldots + \\theta_n x_{in}$  provides an optimal fit to the data.  The algorithm that does this is called **gradient descent**.  By convention, we always set the first component of the vector $\\mathbf{x}_i$ equal to 1, so that $x_{i0} = 1$ for all $i = 1, \\dots, m$.  This is because we need to have the constant term $\\theta_0$ in the expression for $h_\\theta(\\mathbf{x}_i)$.\n",
    "\n",
    "The gradient descent algorithm will find the parameters $\\theta = (\\theta_0, \\theta_1 \\ldots, \\theta_n)$ that minimize the function\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m ( h_{\\theta}( \\mathbf{x}_i ) - y_i )^2 \\, , $$\n",
    "\n",
    "where $$ h_{\\theta}(\\mathbf{x}_i) = \\theta_0 x_{i0} + \\theta_2 x_{i2} + \\ldots + \\theta_n x_{in} = \\sum_{j=0}^n \\theta_j x_{ij} $$\n",
    "\n",
    "This function $J(\\theta)$ is called the **residual sum of squares** (RSS) in statistics, and in the machine learning literature it is often called a **cost function**.  It is an average of the sum of the squared distances between each $h_{\\theta}(\\mathbf{x}_i)$ and the target variable $y_i$, and it measures how tightly our function $h_\\theta$ fits the data.  \n",
    "\n",
    "Let's code up this cost function in Python using numpy's linear algebra capabilities.  In order to do this, we should write $J(\\theta)$ in matrix form.  If we put each feature vector $\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_m$ as the rows of a matrix $X$ and the labels $y_0, y_1, \\ldots, y_m$ in a column vector $\\mathbf{y}$, then we have \n",
    "\n",
    "<br/>\n",
    "$$ X = \n",
    "\\begin{bmatrix}\n",
    "1 & x_{12} & x_{13} & \\cdots & x_{1n} \\\\\n",
    "1 & x_{22} & x_{23} & \\cdots & x_{2n} \\\\\n",
    "\\vdots & \\vdots & & & \\vdots \\\\\n",
    "1 & x_{m2} & x_{m3} & \\cdots & x_{mn}\n",
    "\\end{bmatrix} \\, , \\quad\n",
    "\\mathbf{y} = \n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_m\n",
    "\\end{bmatrix} \\, , \\quad\n",
    "\\theta =\n",
    "\\begin{bmatrix}\n",
    "\\theta_1 & \\theta_2 & \\cdots & \\theta_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "<br\\>\n",
    "\n",
    "and if $\\theta^T$ is the transpose of $\\theta$, then we can write\n",
    "\n",
    "<br/>\n",
    "$$ X \\theta^T - \\mathbf{y} = \n",
    "\\begin{bmatrix}\n",
    "h_\\theta(\\mathbf{x}_1) - y_1 \\\\\n",
    "h_\\theta(\\mathbf{x}_2) - y_2 \\\\\n",
    "\\vdots \\\\\n",
    "h_\\theta(\\mathbf{x}_m) - y_m\n",
    "\\end{bmatrix} \\, .\n",
    "$$\n",
    "<br/>\n",
    "\n",
    "Therefore, if we square each entry of $X \\theta^T - \\mathbf{y}$, then add all the entries and divide by $2m$, we get the expression for $J(\\theta)$.  Numpy has the capabilities to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(X, y, theta):\n",
    "    '''Compute the cost function. \n",
    "    Inputs:\n",
    "    X is an m by n matrix, where m = # of training examples\n",
    "                                 n = # of features (including the \"1\" column)\n",
    "    y is an m-dimensional vector (array)\n",
    "    theta is an n-dimensional vector (array)'''\n",
    "    \n",
    "    squared_errors = np.power(X*theta.T - y, 2)\n",
    "    return np.sum(squared_errors) / (2 * len(X)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ones</th>\n",
       "      <th>population</th>\n",
       "      <th>profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1101</td>\n",
       "      <td>17.5920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.5277</td>\n",
       "      <td>9.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8.5186</td>\n",
       "      <td>13.6620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0032</td>\n",
       "      <td>11.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.8598</td>\n",
       "      <td>6.8233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ones  population   profit\n",
       "0     1      6.1101  17.5920\n",
       "1     1      5.5277   9.1302\n",
       "2     1      8.5186  13.6620\n",
       "3     1      7.0032  11.8540\n",
       "4     1      5.8598   6.8233"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert column of ones\n",
    "df.insert(0, 'ones', 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97, 2), (1, 2), (97, 1))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the training data X and the target variable y\n",
    "X = df[['ones', 'population']]\n",
    "y = df['profit']\n",
    "\n",
    "# initialize theta to [0 0]\n",
    "theta = np.array([0,0])\n",
    "\n",
    "# transform into numpy matrices so we can do linear algebra with them\n",
    "X, y, theta = np.matrix(X), np.matrix(y).T, np.matrix(theta)\n",
    "X.shape, theta.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.072733877455676"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(X,y,theta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
